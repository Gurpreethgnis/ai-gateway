# AI Gateway Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# Provider API Keys (at least one required)
# =============================================================================

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-...

# OpenAI GPT
OPENAI_API_KEY=sk-...

# Google Gemini
GEMINI_API_KEY=...

# Groq (fast inference)
GROQ_API_KEY=gsk_...

# =============================================================================
# Database (defaults work with docker-compose)
# =============================================================================
# DATABASE_URL=postgresql+asyncpg://gateway:gateway@localhost:5432/gateway

# =============================================================================
# Redis (defaults work with docker-compose)
# =============================================================================
# REDIS_URL=redis://localhost:6379/0

# =============================================================================
# Ollama (local LLM inference)
# =============================================================================
# OLLAMA_URL=http://localhost:11434
# Timeout for listing models (GET /api/tags). Keep under proxy timeout (e.g. 10s) to avoid 503.
# OLLAMA_DISCOVERY_TIMEOUT_SECONDS=8

# =============================================================================
# Routing Preferences
# =============================================================================

# 0.0 = cheapest models, 1.0 = highest quality
DEFAULT_COST_QUALITY_BIAS=0.3

# 0.0 = fastest models, 1.0 = highest quality
DEFAULT_SPEED_QUALITY_BIAS=0.5

# Enable automatic fallback on errors
DEFAULT_CASCADE_ENABLED=true

# =============================================================================
# Caching
# =============================================================================

# Layer 1: Exact response caching
ENABLE_RESPONSE_CACHE=true

# Layer 4: Context compression for local models
ENABLE_CONTEXT_COMPRESSION=true
COMPRESSION_MODEL=llama3.2:3b

# =============================================================================
# Authentication
# =============================================================================

# Enable login for dashboard access
ENABLE_DASHBOARD_AUTH=true

# Secret key for session tokens (CHANGE IN PRODUCTION!)
SESSION_SECRET_KEY=change-me-in-production-use-long-random-string

# Session duration in hours
SESSION_EXPIRY_HOURS=24

# Allow new user registration
ALLOW_REGISTRATION=false

# =============================================================================
# Docker Ports (optional)
# =============================================================================
# PORT=8000
# POSTGRES_PORT=5432
# REDIS_PORT=6379
# OLLAMA_PORT=11434

# =============================================================================
# Ollama Performance Tuning
# =============================================================================
# OLLAMA_NUM_PARALLEL=2
# OLLAMA_MAX_LOADED_MODELS=2
